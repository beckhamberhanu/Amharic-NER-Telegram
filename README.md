EthioMart-NER
This project focuses on fine-tuning a Named Entity Recognition (NER) system for Amharic text to extract key business entities such as product names, prices, and locations from Ethiopian e-commerce Telegram channels. The extracted data will be used to build a centralized marketplace, EthioMart, consolidating product listings from multiple Telegram vendors.

Project Structure
plaintext
Copy
Edit
EthioMart-NER/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ ci.yml                      # GitHub Actions CI/CD pipeline configuration
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                            # Raw data collected from Telegram
â”‚   â”œâ”€â”€ processed/                       # Preprocessed and labeled data
â”‚   â”œâ”€â”€ conll/                          # Labeled data in CoNLL format for model training
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_Data_Ingestion.ipynb         # Data scraping and Telegram message collection
â”‚   â”œâ”€â”€ 02_Data_Preprocessing.ipynb     # Cleaning, tokenization, and formatting
â”‚   â”œâ”€â”€ 03_NER_Finetuning.ipynb         # Fine-tuning NER models
â”‚   â”œâ”€â”€ 04_Model_Evaluation.ipynb       # Model comparison and performance analysis
â”‚   â”œâ”€â”€ 05_Model_Interpretability.ipynb # SHAP & LIME explanations
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ data_ingestion.py               # Fetches messages from Telegram channels
â”‚   â”œâ”€â”€ data_preprocessing.py           # Tokenization and text normalization
â”‚   â”œâ”€â”€ labeling.py                     # Converts labeled data into CoNLL format
â”‚   â”œâ”€â”€ ner_training.py                 # Fine-tunes NER models
â”‚   â”œâ”€â”€ model_evaluation.py             # Compares multiple models
â”‚   â”œâ”€â”€ interpretability.py             # Model interpretability with SHAP/LIME
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ trained_models/                  # Saved fine-tuned models
â”‚   â”œâ”€â”€ results/                         # Model performance reports
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_data_preprocessing.py       # Unit tests for preprocessing functions
â”‚   â”œâ”€â”€ test_ner_training.py             # Unit tests for model training pipeline
â”œâ”€â”€ .gitignore                           # Ignore unnecessary files and directories
â”œâ”€â”€ README.md                            # Project overview and setup guide
â”œâ”€â”€ requirements.txt                     # Python dependencies
â”œâ”€â”€ dvc.yaml                             # DVC pipeline for dataset versioning
â”œâ”€â”€ .env                                 # Environment variables (Telegram API credentials)
â””â”€â”€ LICENSE                              # License information
Script Functionalities
data_ingestion.py - Scrapes messages from Ethiopian e-commerce Telegram channels and stores raw data in a structured format.
data_preprocessing.py - Tokenizes Amharic text, normalizes words, and structures data for entity extraction.
labeling.py - Converts a manually labeled dataset into the CoNLL format for Named Entity Recognition (NER) training.
ner_training.py - Fine-tunes transformer-based NER models (e.g., XLM-Roberta, DistilBERT, mBERT) on the labeled dataset.
model_evaluation.py - Compares multiple fine-tuned models based on F1-score, precision, recall, and execution speed.
interpretability.py - Uses SHAP & LIME to interpret the predictions of the NER models and identify biases.
Commit Message Guidelines
To maintain a clear and well-organized repository, follow these commit message guidelines:

âœ… Use the imperative mood
âœ… Be concise and descriptive
âœ… Reference tasks where applicable (e.g., #Task1, #Task2)

Example:

plaintext
Copy
Edit
git commit -m "Implement text normalization in preprocessing script (#Task1)"
Usage Instructions
This project provides scripts and notebooks to streamline the NER fine-tuning process for Amharic e-commerce messages.

1ï¸âƒ£ Set Up the Environment
bash
Copy
Edit
# Clone the repository
git clone https://github.com/beckhamberhanu/EthioMart-NER.git
cd EthioMart-NER

# Create and activate a virtual environment (recommended)
python3 -m venv env
source env/bin/activate  # For Mac/Linux
env\Scripts\activate     # For Windows

# Install required dependencies
pip install -r requirements.txt
2ï¸âƒ£ Configure Environment Variables
Create a .env file and add your Telegram API credentials:

plaintext
Copy
Edit
API_ID=your_api_id
API_HASH=your_api_hash
PHONE_NUMBER=your_phone_number
Pipeline Execution Steps
Step 1: Data Ingestion (Scrape Telegram messages)
bash
Copy
Edit
python scripts/data_ingestion.py
âœ… Fetches messages from Telegram channels and stores them in /data/raw/.

Step 2: Data Preprocessing (Tokenization & Cleaning)
bash
Copy
Edit
python scripts/data_preprocessing.py
âœ… Cleans and tokenizes text, then saves structured data in /data/processed/.

Step 3: Annotate & Label Data (Convert dataset to CoNLL format)
bash
Copy
Edit
python scripts/labeling.py
âœ… Converts labeled messages into CoNLL format for training.

Step 4: Train NER Model (Fine-tune transformer-based models)
bash
Copy
Edit
python scripts/ner_training.py
âœ… Fine-tunes XLM-Roberta, mBERT, or DistilBERT models.

Step 5: Evaluate Model Performance (Compare multiple models)
bash
Copy
Edit
python scripts/model_evaluation.py
âœ… Compares models based on F1-score, precision, recall.

Step 6: Interpret Model Predictions (Using SHAP & LIME)
bash
Copy
Edit
python scripts/interpretability.py
âœ… Uses SHAP & LIME to analyze how the model makes predictions.

Results & Findings
ğŸ“Œ Models Trained:

XLM-Roberta (Base Model)
DistilBERT (Multilingual)
mBERT (Multilingual BERT)
ğŸ“Œ Best Model Performance (NER on Amharic Texts)

Model	Precision	Recall	F1-score
XLM-Roberta	X.XX	X.XX	X.XX
DistilBERT	X.XX	X.XX	X.XX
mBERT	X.XX	X.XX	X.XX
ğŸ“Œ Key Business Insights:

Successfully extracted product names, prices, and locations from Ethiopian e-commerce Telegram channels.
Fine-tuned models show promising results, improving entity recognition accuracy for Amharic text.
SHAP & LIME analysis provided transparency into how models make entity predictions.
Future Work & Improvements
ğŸ”¹ Expand dataset with more annotated samples to improve model accuracy.
ğŸ”¹ Test with Amharic-specific pre-trained models (AfroXLMR, AmRoBERTa) for potentially better results.
ğŸ”¹ Develop a real-time API for seamless integration into the EthioMart platform.
ğŸ”¹ Enhance model interpretability by combining SHAP with rule-based approaches for better business explainability.
